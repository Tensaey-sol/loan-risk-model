# ğŸ“Š Loan Risk Model

This repository contains the implementation of an end-to-end machine learning pipeline for **Loan Risk Model**, a credit risk scoring system developed for a hypothetical bank's buy-now-pay-later service in partnership with an eCommerce platform. The project focuses on building, deploying, and automating a credit risk model using RFM-based proxy variables, feature engineering, and model training, with deployment via FastAPI and CI/CD integration.

---

## ğŸš€ Getting Started

Follow these steps to set up the project locally:

### 1. Clone the Repository

```bash
git clone https://github.com/Tensaey-sol/loan-risk-model.git
cd loan-risk-model
```

### 2. Set Up a Virtual Environment

```bash
python -m venv .venv
```

Activate it:

- **Windows:**

  ```bash
  .venv\Scripts\activate
  ```

- **macOS/Linux:**

  ```bash
  source .venv/bin/activate
  ```

### 3. Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ğŸ“‚ Project Structure

```
loan-risk-model/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml             # GitHub Actions workflow for CI/CD
â”œâ”€â”€ .gitignore                 # Ignore rules for Git
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks for EDA and experimentation
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ tests/                     # Unit tests for scripts and functions
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ src/                       # Scripts for data processing, feature engineering, and API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ data/                      # Raw and processed datasets (ignored via .gitignore)
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â””â”€â”€ .venv/                     # Local virtual environment (ignored via .gitignore)
```

---

## âš™ï¸ GitHub Actions CI

A CI workflow is configured to run on every push to the main branch:

- Uses **Python 3.x** (specified in `requirements.txt`)
- Installs dependencies from `requirements.txt`
- Runs a linter (e.g., flake8) for code style checks
- Executes unit tests in `/tests` using pytest

See `.github/workflows/ci.yml` for setup and the **Actions** tab of the GitHub repository for its status.

---

## ğŸ›  Tools & Technologies

- Python **3.13.1**
- `venv` for isolated Python environments
- **VSCode** (Recommended editor)
- Scikit-learn for model training and pipelines
- MLflow for experiment tracking and model registry
- FastAPI and Uvicorn for API deployment
- Docker and docker-compose for containerization
- Xverse and WoE for feature engineering
- Jupyter Notebooks for exploratory data analysis
- Git & GitHub for version control
- GitHub Actions for CI/CD automation
- Pytest for unit testing
- Flake8 or Black for linting

---

## Credit Scoring Business Understanding

### How does the Basel II Accordâ€™s emphasis on risk measurement influence our need for an interpretable and well-documented model?

The Basel II and Basel III frameworks emphasize robust credit risk measurement to ensure financial institutions maintain adequate capital reserves and manage risk exposures effectively. Basel IIâ€™s focus on risk-weighted assets and credit risk assessment requires models to be interpretable and well-documented to comply with regulatory oversight, support auditability, and align with the institutionâ€™s credit risk strategy. An interpretable model, such as Logistic Regression with Weight of Evidence (WoE), enables clear mapping of features to risk outcomes, facilitating transparency for regulators and stakeholders. Well-documented models ensure traceability of credit decisions, supporting the boardâ€™s responsibility to promote a sound credit risk management environment, as mandated by Basel III.

### Why is creating a proxy variable necessary, and what are the potential business risks of making predictions based on this proxy?

Without a direct "default" label in the dataset, a proxy variable (e.g., `is_high_risk` derived from RFM clustering) is essential to estimate credit risk based on behavioral patterns like low transaction recency, frequency, or monetary value. This proxy enables model training but risks misclassification if it poorly correlates with actual default behavior, as highlighted in credit risk literature. Business risks include approving high-risk customers, leading to increased loan losses, or rejecting low-risk customers, resulting in lost revenue. These errors could undermine profitability and violate Basel IIIâ€™s requirement to maintain credit risk within acceptable parameters, potentially impacting the institutionâ€™s financial stability.

### What are the key trade-offs between using a simple, interpretable model (like Logistic Regression with WoE) versus a complex, high-performance model (like Gradient Boosting) in a regulated financial context?

In a regulated financial context, simple models like Logistic Regression with WoE offer high interpretability, aligning with Basel II and IIIâ€™s emphasis on transparent credit risk assessment and governance. They allow stakeholders to understand feature contributions to risk scores, supporting compliance and audit requirements. However, they may underperform in capturing complex, non-linear patterns in data, potentially reducing predictive accuracy. Complex models like Gradient Boosting excel at modeling intricate relationships, improving performance metrics like ROC-AUC, but their "black-box" nature complicates regulatory justification and increases scrutiny from risk management and audit functions. The trade-off balances regulatory compliance and explainability against predictive power, with simpler models often preferred for their alignment with the 5 Cs of Credit and credit policy frameworks.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™‹â€â™€ï¸ Questions or Suggestions?

Feel free to open an issue or submit a pull request if youâ€™d like to contribute or raise a question.
